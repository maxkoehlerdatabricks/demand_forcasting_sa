{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181f0a6f-cdee-42f8-ac65-f1db590831f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown('reset_all_data', 'false', ['true', 'false'], 'Reset all data')\n",
    "dbutils.widgets.text('catalogName',  'maxkoehler_demos' , 'Catalog Name')\n",
    "dbutils.widgets.text('dbName',  'demand_db' , 'Database Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0596121c-f2b2-478d-afaa-c54b708f805a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting ./_resources/01-data-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec619a7e-3142-4fdc-9cd0-bec190e6c471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalogName = dbutils.widgets.get('catalogName')\n",
    "dbName = dbutils.widgets.get('dbName')\n",
    "reset_all_data = dbutils.widgets.get('reset_all_data') == 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "093a5481-2eca-4996-8140-b43d1c8d2116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(catalogName)\n",
    "print(dbName)\n",
    "print(reset_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8984a9c-681f-41c5-bf8f-aed0e37365db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalogName}\")\n",
    "spark.sql(f\"\"\"USE CATALOG {catalogName}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28829ad0-e19a-4b59-b858-6c2304f5e21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {dbName}\")\n",
    "spark.sql(f\"\"\"USE {dbName}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e519438d-119f-4241-9d44-919490fd3978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hierarchical Time Series Generator\n",
    "This notebook-section simulates hierarchical time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e7c35fb-8df2-4028-9316-1459cf1b47e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simulate demand series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014de8dc-b5a8-46a8-8762-25d633f8c1bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Python Packages\n",
    "#################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil import rrule\n",
    "\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, concat_ws\n",
    "from pyspark.sql.types import StructType,StructField, StringType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8198edc2-4898-4c39-96d0-9b153b923e60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Parameters\n",
    "#################################################\n",
    "n=3 # Number of SKU's per product\n",
    "ts_length_in_years = 3 # Length of a time series in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd98ef2-12ea-4a32-b64e-887fb54a882a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Create a Product Table\n",
    "#################################################\n",
    "\n",
    "data = [(\"Lidar\",  \"LID\"),\n",
    "    (\"Camera\", \"CAM\"),\n",
    "    (\"Long Range Radar\", \"LRR\"),\n",
    "    (\"Short Range Radar\", \"SRR\")\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Product\",StringType(),True), \\\n",
    "    StructField(\"SKU_Prefix\",StringType(),True)\n",
    "  ])\n",
    " \n",
    "product_identifier_lookup = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "display(product_identifier_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b7570da-56e5-48ed-b7eb-921580c69c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Create a product hierarchy by simulating SKUs for each product\n",
    "#################################################\n",
    "\n",
    "# Define schema of output data-frame\n",
    "product_hierarchy_schema = StructType([StructField(\"SKU_Postfix\", StringType(), True)] + product_identifier_lookup.schema.fields)\n",
    "\n",
    "# Help-function to generate a random string\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "# Create a Pandas UDF to simulate unique SKU's, i.e. n random strings without repetition\n",
    "def id_sequence_generator(pdf):\n",
    "  random.seed(123)\n",
    "  res = set()\n",
    "  while True:\n",
    "    res.add(id_generator())\n",
    "    if len(res) >= n:\n",
    "      break\n",
    "  \n",
    "  pdf_out = pd.DataFrame()\n",
    "  pdf_out[\"SKU_Postfix\"] = list(res)\n",
    "  pdf_out[\"Product\"] = pdf[\"Product\"].iloc[0]\n",
    "  pdf_out[\"SKU_Prefix\"] = pdf[\"SKU_Prefix\"].iloc[0]\n",
    "  \n",
    "  return pdf_out\n",
    "\n",
    "# Apply the Pandas UDF and clean up\n",
    "product_hierarchy = ( \\\n",
    "  product_identifier_lookup \\\n",
    "  .groupby(\"SKU_Prefix\", \"Product\") \\\n",
    "  .applyInPandas(id_sequence_generator, product_hierarchy_schema) \\\n",
    "  .withColumn(\"SKU\", concat_ws('_',\"SKU_Prefix\",\"SKU_Postfix\")) \\\n",
    "  .select(\"Product\",\"SKU\")\n",
    "      )\n",
    "\n",
    "# Check that the number of rows is what is expected\n",
    "assert product_hierarchy.count() == (n * product_identifier_lookup.count()), \"Number of rows in final table contradicts with input parameters\"\n",
    "\n",
    "display(product_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a640b87-f05b-4454-a1cd-f8c42b9284cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Create a Pandas DataFrame with common dates for ALL time series\n",
    "#################################################\n",
    "# End Date: Make it a Monday the week before\n",
    "end_date = datetime.datetime.today()\n",
    "end_date = end_date + datetime.timedelta(-end_date.weekday() -7 )\n",
    "\n",
    "# Start date: Is a monday, since we will go back integer number of weeks\n",
    "start_date = end_date + relativedelta(weeks= (-ts_length_in_years * 52))\n",
    "\n",
    "# Make a sequence \n",
    "date_range = list(rrule.rrule(rrule.WEEKLY, dtstart=start_date, until=end_date))\n",
    "date_range = [x.date() for x in date_range]\n",
    "\n",
    "date_range = pd.DataFrame(date_range, columns =['Date'])\n",
    "\n",
    "display(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4998a14f-b90e-43dc-b8f0-5bb1497e10c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Create a Pandas DataFrame with common dates for ALL time series\n",
    "#################################################\n",
    "# End Date: Make it a Monday the week before\n",
    "end_date = datetime.datetime.today()\n",
    "end_date = end_date + datetime.timedelta(-end_date.weekday() -7 )\n",
    "\n",
    "# Start date: Is a monday, since we will go back integer number of weeks\n",
    "start_date = end_date + relativedelta(weeks= (-ts_length_in_years * 52))\n",
    "\n",
    "# Make a sequence \n",
    "date_range = list(rrule.rrule(rrule.WEEKLY, dtstart=start_date, until=end_date))\n",
    "date_range = [x.date() for x in date_range]\n",
    "\n",
    "date_range = pd.DataFrame(date_range, columns =['Date'])\n",
    "\n",
    "\n",
    "# Derive X-mas Correction factor for demand\n",
    "date_range = date_range.assign(Week = pd.DatetimeIndex(date_range['Date']).isocalendar().week.tolist())\n",
    "\n",
    "conditions_xmas = [\n",
    "      date_range.Week == 51,\n",
    "      date_range.Week >= 52,\n",
    "      date_range.Week == 1,\n",
    "      date_range.Week == 2,\n",
    "      date_range.Week == 3,\n",
    "      date_range.Week == 4\n",
    "    ]\n",
    "\n",
    "choices_xmas = [\n",
    "  0.85,\n",
    "  0.8,\n",
    "  1.1,\n",
    "  1.15,\n",
    "  1.1,\n",
    "  1.05\n",
    "]\n",
    "\n",
    "date_range[ \"Factor_XMas\" ] = np.select(conditions_xmas, choices_xmas, default= 1.0)\n",
    "\n",
    "display(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3abf638-a97b-42fd-bdb6-70ad9a374b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Enhance the product table with parameters for simulating time series\n",
    "#################################################\n",
    "\n",
    "# Get a list of all products from the hierarchy table and generate a list \n",
    "from  pyspark.sql.types import FloatType, ArrayType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# Define schema for new columns\n",
    "arma_schema = StructType(\n",
    "  [\n",
    "    StructField(\"Variance_RN\", FloatType(), True),\n",
    "    StructField(\"Offset_RN\", FloatType(), True),\n",
    "    StructField(\"AR_Pars_RN\", ArrayType(FloatType()), True),\n",
    "    StructField(\"MA_Pars_RN\", ArrayType(FloatType()), True)\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Generate random numbers for the ARMA process\n",
    "np.random.seed(123)\n",
    "n_ = product_identifier_lookup.count()\n",
    "variance_random_number = list(abs(np.random.normal(100, 50, n_)))\n",
    "offset_random_number = list(np.maximum(abs(np.random.normal(10000, 5000, n_)), 4000))\n",
    "ar_length_random_number = np.random.choice(list(range(1,4)), n_)\n",
    "ar_parameters_random_number = [np.random.uniform(low=0.1, high=0.9, size=x) for x in ar_length_random_number] \n",
    "ma_length_random_number = np.random.choice(list(range(1,4)), n_)\n",
    "ma_parameters_random_number = [np.random.uniform(low=0.1, high=0.9, size=x) for x in ma_length_random_number] \n",
    "\n",
    "\n",
    "# Collect in a dataframe\n",
    "pdf_helper = (pd.DataFrame(variance_random_number, columns =['Variance_RN']). \n",
    "              assign(Offset_RN = offset_random_number).\n",
    "              assign(AR_Pars_RN = ar_parameters_random_number).\n",
    "              assign(MA_Pars_RN = ma_parameters_random_number) \n",
    "             )\n",
    "\n",
    "# Append column-wise\n",
    "spark_df_helper = spark.createDataFrame(pdf_helper, schema=arma_schema)\n",
    "spark_df_helper = spark_df_helper.withColumn(\n",
    "  \"row_id\", F.row_number().over(Window().partitionBy().orderBy(\"Offset_RN\")) \n",
    "  # dummy window just to get matching row numbers\n",
    "  )\n",
    "product_identifier_lookup_with_row_ids = product_identifier_lookup.withColumn(\n",
    "  \"row_id\", F.row_number().over(Window().partitionBy().orderBy(\"Product\"))\n",
    "  # dummy window just to get matching row numbers\n",
    "  )\n",
    "product_identifier_lookup_extended = product_identifier_lookup_with_row_ids.join(\n",
    "  spark_df_helper, (\"row_id\")\n",
    "  ).drop(\"row_id\")\n",
    "product_identifier_lookup = product_identifier_lookup_with_row_ids.drop(\"row_id\")\n",
    "product_hierarchy_extended = product_hierarchy.join(product_identifier_lookup_extended.drop(\"SKU_Prefix\"), [\"Product\"], how = \"inner\")\n",
    "assert product_identifier_lookup_extended.count() == product_identifier_lookup.count(), \"Ambiguous number of rows after join\"\n",
    "\n",
    "display(product_identifier_lookup_with_row_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc46a423-a751-4664-ba43-1e67eaab9b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(product_hierarchy_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80b7ee76-50c7-4502-aeab-4cf9d9d422ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql.functions import row_number, sqrt, round\n",
    "\n",
    "#################################################\n",
    "# Generate an individual time series for each Product-SKU combination\n",
    "#################################################\n",
    "\n",
    "# function to generate an ARMA process\n",
    "def generate_arma(arparams, maparams, var, offset, number_of_points, plot):\n",
    "  np.random.seed(123)\n",
    "  ar = np.r_[1, arparams] \n",
    "  ma = np.r_[1, maparams] \n",
    "  y = sm.tsa.arma_generate_sample(ar, ma, number_of_points, scale=var, burnin= 3000) + offset\n",
    "\n",
    "  \n",
    "  if plot:\n",
    "    x = np.arange(1, len(y) +1)\n",
    "    plt.plot(x, y, color =\"red\")\n",
    "    plt.show()\n",
    "    \n",
    "  return(y)\n",
    "\n",
    "\n",
    "#Schema for output dataframe\n",
    "sku_ts_schema = StructType(  product_hierarchy.schema.fields + \n",
    "                    [\n",
    "                      StructField(\"Date\", DateType(), True),\n",
    "                      StructField(\"Demand\", FloatType(), True),\n",
    "                      StructField(\"Factor_XMas\", FloatType(), True),                     \n",
    "                      StructField(\"Row_Number\", FloatType(), True) \n",
    "                    ])\n",
    "\n",
    "\n",
    "def time_series_generator_pandas_udf(pdf):\n",
    "  out_df = date_range.assign(\n",
    "   Demand = generate_arma(arparams = pdf.AR_Pars_RN.iloc[0], \n",
    "                          maparams= pdf.MA_Pars_RN.iloc[0], \n",
    "                          var = pdf.Variance_RN.iloc[0], \n",
    "                          offset = pdf.Offset_RN.iloc[0], \n",
    "                          number_of_points = date_range.shape[0], \n",
    "                          plot = False),\n",
    "    Product = pdf.Product.iloc[0],\n",
    "    SKU = pdf.SKU.iloc[0]\n",
    "  )\n",
    "\n",
    "  out_df = out_df[[\"Product\", \"SKU\", \"Date\", \"Demand\", \"Factor_XMas\"]]\n",
    "  \n",
    "  out_df[\"Row_Number\"] = range(0,len(out_df))\n",
    "\n",
    "  return(out_df)\n",
    "\n",
    "demand_df = ( \n",
    "  product_hierarchy_extended \n",
    "  .groupby(\"Product\", \"SKU\") \n",
    "  .applyInPandas(time_series_generator_pandas_udf, sku_ts_schema)\n",
    "  .withColumn(\"Demand\" , col(\"Demand\") * col(\"Factor_XMas\"))\n",
    "  .withColumn(\"Demand\" , round(col(\"Demand\")))\n",
    "  .select(col(\"Product\"), col(\"SKU\"), col(\"Date\"), col(\"Demand\") )\n",
    ") \n",
    "\n",
    "\n",
    "display(demand_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8449e45a-be5d-46b3-9210-e41c9a4ce15f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4301edac-ecab-404b-9146-41d5f031bb2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spark.sql(\"DROP TABLE IF EXISTS part_level_demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd2af6ec-e7ba-409b-b971-01edc6809c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demand_df.write.mode(\"overwrite\").saveAsTable(\"part_level_demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cc01afb-2089-4e43-985f-17b8b6698b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simulate BoM Data\n",
    "This notebook section simulates Bill-Of-Material data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f057bb4c-36bf-4020-9c94-43d72741c8e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "665ef211-67b8-4bb0-9b2a-5b607a49ef15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfa7432-16ca-4f66-9900-463cadbad438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def generate_random_strings(n):\n",
    "  random.seed(123)\n",
    "  random_mat_numbers = set()\n",
    "  while True:\n",
    "    random_mat_numbers.add(id_generator(size=5))\n",
    "    if len(random_mat_numbers) >= n:\n",
    "      break\n",
    "  return(random_mat_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ee53c9f-1148-4140-9a61-0b9130db1136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extend_one_step(node_from_):\n",
    "  res_ = [  ]\n",
    "  node_list_to_be_extended_ = [  ]\n",
    "  # second level\n",
    "  random_split_number = random.randint(2, 4)\n",
    "  for i in range(random_split_number):\n",
    "    node_to = random_mat_numbers.pop()\n",
    "    node_list_to_be_extended_.append(node_to)\n",
    "    res_.append((node_to, node_from_))\n",
    "  return res_, node_list_to_be_extended_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d900647-6019-488a-82f3-abc8b6bcce21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extend_one_level(node_list_to_be_extended, level, sku):\n",
    "  \n",
    "  \n",
    "  print(f\"\"\"In  'extend_one_level': level={level} and sku = {sku}  \"\"\")\n",
    "  \n",
    "  if level == 1:\n",
    "    head_node = random_mat_numbers.pop() \n",
    "    node_list_to_be_extended_one_level = [ ]\n",
    "    node_list_to_be_extended_one_level.append(head_node)\n",
    "    res_one_level = [ (head_node, sku) ]\n",
    "  else:\n",
    "    res_one_level = [ ]\n",
    "    node_list_to_be_extended_one_level = [ ]\n",
    "    \n",
    "    if len(node_list_to_be_extended) > 2:\n",
    "      node_list_to_be_extended_ = node_list_to_be_extended[ : 3 ]\n",
    "    else:\n",
    "      node_list_to_be_extended_ = node_list_to_be_extended\n",
    "\n",
    "    for node in node_list_to_be_extended_:\n",
    "      res_one_step = [ ]\n",
    "      node_list_to_be_extended_one_step = [ ]\n",
    "      \n",
    "      res_one_step, node_list_to_be_extended_one_step = extend_one_step(node)    \n",
    "      res_one_level.extend(res_one_step)\n",
    "      node_list_to_be_extended_one_level.extend(node_list_to_be_extended_one_step)\n",
    "  \n",
    "  return res_one_level, node_list_to_be_extended_one_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3da9c51a-c261-41d6-933f-55461517462b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Generate a set of material numbers\n",
    "random_mat_numbers = generate_random_strings(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2231bc1-916f-4f63-ae2b-2c0286fd3e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a listof all SKU's\n",
    "#demand_df = spark.read.table(f\"part_level_demand\")\n",
    "#all_skus = demand_df.select('SKU').distinct().rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e587087-5014-4467-b1a4-67ed951de8e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Create a list of all SKU's\n",
    "demand_df = spark.read.table(f\"part_level_demand\")\n",
    "all_skus = demand_df.select('SKU').distinct().collect()\n",
    "all_skus = [row['SKU'] for row in all_skus]\n",
    "all_skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a28889a2-1bd4-428b-b151-f283d94b0268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generaze edges\n",
    "depth = 3\n",
    "edge_list = [ ]\n",
    "\n",
    "for sku in all_skus: \n",
    "  new_node_list = [ ]\n",
    "  for level_ in range(1, (depth + 1)):\n",
    "    new_edge_list, new_node_list = extend_one_level(new_node_list, level = level_, sku=sku)\n",
    "    edge_list.extend(new_edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87aab489-7a42-470e-aa04-b57848f17e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the graph \n",
    "g=nx.DiGraph()\n",
    "g.add_edges_from(edge_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d173a441-1cc6-4d6b-b042-01cc8870eca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign a quantity for the graph\n",
    "edge_df = nx.to_pandas_edgelist(g)\n",
    "edge_df = edge_df.assign(qty = np.where(edge_df.target.str.len() == 10, 1, np.random.randint(1,4, size=edge_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bb4d53c-8feb-4703-abda-8c248822c3e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89ae48c0-3de9-4d21-837f-5199b8274743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a50033d4-3f47-44a3-b448-1ae8b6edf380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e76e8dc1-03a6-427a-8f99-842b54491593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "sku_list = [row.SKU for row in demand_df.withColumn(\"SKU\", split(col(\"SKU\"), \"_\")[0]).select(\"SKU\").distinct().collect()]\n",
    "search_expression = \"|\".join(sku_list) + \"_.*\"\n",
    "search_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc23e5c4-dac7-4b45-89a2-51da3e77203a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create the final mat number to sku mapper \n",
    "final_mat_number_to_sku_mapper = edge_df[edge_df.target.str.match(search_expression)][[\"source\",\"target\"]]\n",
    "final_mat_number_to_sku_mapper = final_mat_number_to_sku_mapper.rename(columns={\"source\": \"final_mat_number\", \"target\": \"sku\"} )\n",
    "final_mat_number_to_sku_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816e9d53-9038-429a-a89b-c21f8cf2761b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create the fnal mat number to sku mapper\n",
    "#final_mat_number_to_sku_mapper = edge_df[edge_df.target.str.match(search_expression)][[\"source\",\"target\"]]\n",
    "#final_mat_number_to_sku_mapper = final_mat_number_to_sku_mapper.rename(columns={\"source\": \"final_mat_number\", \"target\": \"sku\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "621a73ba-8c24-4b03-9bd3-a189c13d1c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create BoM\n",
    "bom = edge_df[~edge_df.target.str.match(search_expression)]\n",
    "bom = bom.rename(columns={\"source\": \"material_in\", \"target\": \"material_out\"} )\n",
    "bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d0ddb59-5e10-46e5-98ac-731cf79a78b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bom_df = spark.createDataFrame(bom) \n",
    "final_mat_number_to_sku_mapper_df = spark.createDataFrame(final_mat_number_to_sku_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4507078-40a5-4ff5-9b40-de8968522579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register tables in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0498228d-8cea-4cf2-bd88-5256bff19476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bom_df.write.mode(\"overwrite\").saveAsTable(\"bom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fff1558-81bf-4b21-968c-d69ca5433395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_mat_number_to_sku_mapper_df.write.mode(\"overwrite\").saveAsTable(\"sku_mapper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d11a4c-902a-4b8c-bc29-32d0688385f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from sku_mapper\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c63453e1-2e40-4a71-9159-e39c19139a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from bom\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2911b056-ca48-447d-a165-c048273c3f51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Ending ./_resources/01-data-generator\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01-data-generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
